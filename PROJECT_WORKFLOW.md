# ğŸ“Š QUY TRÃŒNH Dá»° ÃN PHÃ‚N TÃCH Cáº¢M XÃšC THá»Š TRÆ¯á»œNG CHá»¨NG KHOÃN

## ğŸ¯ Tá»•ng Quan Dá»± Ãn

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n tÃ­ch cáº£m xÃºc (Sentiment Analysis) tá»« cÃ¡c bÃ¬nh luáº­n vá» thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam, sá»­ dá»¥ng káº¿t há»£p AI generative (Gemini) vÃ  cÃ¡c mÃ´ hÃ¬nh Machine Learning/Deep Learning.

---

## ğŸ”„ SÆ  Äá»’ QUY TRÃŒNH Tá»”NG THá»‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Dá»® LIá»†U THÃ” (RAW DATA)                       â”‚
â”‚                          Data.json (3.4MB)                          â”‚
â”‚                    VIC_price.csv (GiÃ¡ cá»• phiáº¿u)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BÆ¯á»šC 1: KIá»‚M TRA & GÃN NHÃƒN                      â”‚
â”‚                        CheckData.ipynb                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Äá»c dá»¯ liá»‡u thÃ´ tá»« Data.json                                â”‚ â”‚
â”‚  â”‚ â€¢ Sá»­ dá»¥ng Gemini AI (gemma-3-27b-it)                          â”‚ â”‚
â”‚  â”‚ â€¢ Lá»c bá»: spam, tá»¥c tÄ©u, ná»™i dung khÃ´ng liÃªn quan            â”‚ â”‚
â”‚  â”‚ â€¢ GÃ¡n nhÃ£n:                                                   â”‚ â”‚
â”‚  â”‚   - Sentiment: TÃ­ch cá»±c/TiÃªu cá»±c/BÃ¬nh thÆ°á»ng                 â”‚ â”‚
â”‚  â”‚   - Aspect: GiÃ¡/Kinh doanh/ChÃ­nh sÃ¡ch/Cáº£m xÃºc/...            â”‚ â”‚
â”‚  â”‚ â€¢ Xuáº¥t: Data_T9_Labeled_Final.json                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BÆ¯á»šC 2: PHÃ‚N TÃCH KHÃM PHÃ Dá»® LIá»†U                 â”‚
â”‚                         EDA_Data.ipynb                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Thá»‘ng kÃª mÃ´ táº£ (describe statistics)                        â”‚ â”‚
â”‚  â”‚ â€¢ PhÃ¢n bá»‘ nhÃ£n (sentiment & aspect distribution)              â”‚ â”‚
â”‚  â”‚ â€¢ PhÃ¢n tÃ­ch Ä‘á»™ dÃ i vÄƒn báº£n                                    â”‚ â”‚
â”‚  â”‚ â€¢ Word Cloud & tá»« khÃ³a phá»• biáº¿n                               â”‚ â”‚
â”‚  â”‚ â€¢ TÆ°Æ¡ng quan giá»¯a sentiment vÃ  giÃ¡ cá»• phiáº¿u                   â”‚ â”‚
â”‚  â”‚ â€¢ PhÃ¡t hiá»‡n outliers & missing values                         â”‚ â”‚
â”‚  â”‚ â€¢ Visualizations: biá»ƒu Ä‘á»“, heatmap, timeline                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BÆ¯á»šC 3: Xá»¬ LÃ & CHUáº¨N Bá»Š Dá»® LIá»†U                â”‚
â”‚                  (Thá»±c hiá»‡n trong cÃ¡c file model)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ LÃ m sáº¡ch vÄƒn báº£n (text cleaning)                            â”‚ â”‚
â”‚  â”‚ â€¢ Tokenization (tÃ¡ch tá»« tiáº¿ng Viá»‡t)                           â”‚ â”‚
â”‚  â”‚ â€¢ Loáº¡i bá» stopwords                                           â”‚ â”‚
â”‚  â”‚ â€¢ Chuáº©n hÃ³a (lowercase, remove special chars)                 â”‚ â”‚
â”‚  â”‚ â€¢ Feature extraction:                                         â”‚ â”‚
â”‚  â”‚   - TF-IDF (cho ML)                                           â”‚ â”‚
â”‚  â”‚   - Word Embeddings (cho DL)                                  â”‚ â”‚
â”‚  â”‚   - PhoBERT embeddings (cho transformer)                      â”‚ â”‚
â”‚  â”‚ â€¢ Train/Test split (80/20 hoáº·c 70/30)                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                â”‚                â”‚
                â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BÆ¯á»šC 4A: ML    â”‚  â”‚   BÆ¯á»šC 4B: DL    â”‚  â”‚  BÆ¯á»šC 4C: BERT   â”‚
â”‚MachineLearning   â”‚  â”‚ DeepLearning     â”‚  â”‚  PhoBertModel    â”‚
â”‚   Model.ipynb    â”‚  â”‚   Model.ipynb    â”‚  â”‚     .ipynb       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BÆ¯á»šC 5: SO SÃNH & ÄÃNH GIÃ                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Metrics: Accuracy, Precision, Recall, F1-Score              â”‚ â”‚
â”‚  â”‚ â€¢ Confusion Matrix                                            â”‚ â”‚
â”‚  â”‚ â€¢ ROC-AUC Curve                                               â”‚ â”‚
â”‚  â”‚ â€¢ Chá»n mÃ´ hÃ¬nh tá»‘t nháº¥t                                       â”‚ â”‚
â”‚  â”‚ â€¢ LÆ°u model (.pkl, .h5, .pt)                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BÆ¯á»šC 6: TRIá»‚N KHAI á»¨NG Dá»¤NG                      â”‚
â”‚                         Chat_bot.ipynb                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Load mÃ´ hÃ¬nh Ä‘Ã£ train                                       â”‚ â”‚
â”‚  â”‚ â€¢ XÃ¢y dá»±ng chatbot interface                                  â”‚ â”‚
â”‚  â”‚ â€¢ Dá»± Ä‘oÃ¡n sentiment real-time                                 â”‚ â”‚
â”‚  â”‚ â€¢ TÃ­ch há»£p vá»›i API/Web interface                              â”‚ â”‚
â”‚  â”‚ â€¢ Hiá»ƒn thá»‹ káº¿t quáº£ & insights                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CHI TIáº¾T CÃC FILE TRONG Dá»° ÃN

### 1ï¸âƒ£ **CheckData.ipynb** - Data Labeling & Cleaning
**Má»¥c Ä‘Ã­ch:** LÃ m sáº¡ch vÃ  gÃ¡n nhÃ£n dá»¯ liá»‡u thÃ´

**Input:**
- `Data.json` - Dá»¯ liá»‡u bÃ¬nh luáº­n thÃ´ chÆ°a xá»­ lÃ½

**Process:**
1. Äá»c dá»¯ liá»‡u JSON
2. Káº¿t ná»‘i Gemini AI API (gemma-3-27b-it)
3. Xá»­ lÃ½ theo batch (20 items/batch)
4. Lá»c bá»:
   - Ná»™i dung tá»¥c tÄ©u, pháº£n cáº£m
   - Spam quáº£ng cÃ¡o
   - ChÃ o há»i xÃ£ giao vÃ´ nghÄ©a
   - RÃ¡c/nonsense
5. GÃ¡n nhÃ£n cho dá»¯ liá»‡u há»£p lá»‡:
   - **Sentiment:** TÃ­ch cá»±c / TiÃªu cá»±c / BÃ¬nh thÆ°á»ng
   - **Aspect:** Diá»…n biáº¿n giÃ¡ / Kinh doanh / ChÃ­nh sÃ¡ch / Cáº£m xÃºc / Chiáº¿n lÆ°á»£c / Sá»± kiá»‡n / KhÃ¡c

**Output:**
- `Data_T9_Labeled_Final.json` - Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n

**CÃ´ng nghá»‡:**
- Google Generative AI (Gemini)
- Pandas, JSON
- Temperature = 0.0 (Ä‘á»ƒ AI nghiÃªm tÃºc, khÃ´ng sÃ¡ng táº¡o)

---

### 2ï¸âƒ£ **EDA_Data.ipynb** - Exploratory Data Analysis
**Má»¥c Ä‘Ã­ch:** KhÃ¡m phÃ¡ vÃ  hiá»ƒu sÃ¢u vá» dá»¯ liá»‡u

**Input:**
- `Data_T9_Labeled_Final.json` - Dá»¯ liá»‡u Ä‘Ã£ gÃ¡n nhÃ£n
- `VIC_price.csv` - Dá»¯ liá»‡u giÃ¡ cá»• phiáº¿u VIC

**PhÃ¢n tÃ­ch thá»±c hiá»‡n:**

#### ğŸ“Š Thá»‘ng kÃª mÃ´ táº£
- Tá»•ng sá»‘ máº«u
- PhÃ¢n bá»‘ theo sentiment (%)
- PhÃ¢n bá»‘ theo aspect (%)
- Äá»™ dÃ i trung bÃ¬nh cá»§a vÄƒn báº£n

#### ğŸ“ˆ Visualizations
- **Bar charts:** PhÃ¢n bá»‘ sentiment & aspect
- **Pie charts:** Tá»· lá»‡ cÃ¡c nhÃ£n
- **Word Cloud:** Tá»« khÃ³a phá»• biáº¿n theo tá»«ng sentiment
- **Timeline:** Xu hÆ°á»›ng sentiment theo thá»i gian
- **Correlation:** Má»‘i liÃªn há»‡ giá»¯a sentiment vÃ  giÃ¡ cá»• phiáº¿u

#### ğŸ” PhÃ¢n tÃ­ch chuyÃªn sÃ¢u
- Tá»« khÃ³a Ä‘áº·c trÆ°ng cho tá»«ng sentiment
- PhÃ¢n tÃ­ch Ä‘á»™ dÃ i vÄƒn báº£n
- PhÃ¡t hiá»‡n outliers
- Missing values & data quality check

**Output:**
- Insights vá» dá»¯ liá»‡u
- Biá»ƒu Ä‘á»“ & visualizations
- BÃ¡o cÃ¡o EDA

---

### 3ï¸âƒ£ **MachineLearningModel.ipynb** - Traditional ML Models
**Má»¥c Ä‘Ã­ch:** XÃ¢y dá»±ng mÃ´ hÃ¬nh ML cá»• Ä‘iá»ƒn

**Input:**
- `Data_T9_Labeled_Final.json`

**Preprocessing:**
1. Text cleaning (lÃ m sáº¡ch vÄƒn báº£n)
2. Tokenization (tÃ¡ch tá»« tiáº¿ng Viá»‡t - VnCoreNLP/PyVi)
3. Remove stopwords
4. TF-IDF Vectorization

**Models Ä‘Æ°á»£c thá»­ nghiá»‡m:**
- âœ… **Logistic Regression**
- âœ… **Naive Bayes** (MultinomialNB)
- âœ… **Support Vector Machine (SVM)**
- âœ… **Random Forest**
- âœ… **XGBoost**
- âœ… **LightGBM**

**Hyperparameter Tuning:**
- Grid Search CV
- Random Search CV
- Cross-validation (5-fold)

**Evaluation Metrics:**
- Accuracy
- Precision, Recall, F1-Score (macro & weighted)
- Confusion Matrix
- Classification Report

**Output:**
- Trained models (.pkl files)
- Performance comparison table
- Best model selection

---

### 4ï¸âƒ£ **DeepLearningModel.ipynb** - Deep Learning Models
**Má»¥c Ä‘Ã­ch:** XÃ¢y dá»±ng mÃ´ hÃ¬nh Deep Learning

**Input:**
- `Data_T9_Labeled_Final.json`

**Preprocessing:**
1. Text cleaning
2. Tokenization
3. Word Embeddings:
   - Word2Vec (tá»± train hoáº·c pre-trained)
   - GloVe
   - FastText

**Architectures:**
- ğŸ§  **LSTM** (Long Short-Term Memory)
  - Bidirectional LSTM
  - Stacked LSTM
- ğŸ§  **GRU** (Gated Recurrent Unit)
- ğŸ§  **CNN** (Convolutional Neural Network)
  - 1D CNN for text
- ğŸ§  **CNN-LSTM Hybrid**
- ğŸ§  **Attention Mechanism**

**Training Configuration:**
- Loss: Categorical Crossentropy
- Optimizer: Adam
- Batch size: 32/64
- Epochs: 50-100 (vá»›i early stopping)
- Callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

**Regularization:**
- Dropout layers
- L2 regularization
- Batch Normalization

**Output:**
- Trained models (.h5, .keras files)
- Training history (loss & accuracy curves)
- Best model weights

---

### 5ï¸âƒ£ **PhoBertModel.ipynb** - Vietnamese BERT Model
**Má»¥c Ä‘Ã­ch:** Sá»­ dá»¥ng transformer model chuyÃªn cho tiáº¿ng Viá»‡t

**Input:**
- `Data_T9_Labeled_Final.json`

**Model Architecture:**
- ğŸ¤– **PhoBERT** (Pre-trained Vietnamese BERT)
  - vinai/phobert-base
  - vinai/phobert-large

**Approach:**
1. **Fine-tuning PhoBERT:**
   - Load pre-trained PhoBERT
   - Add classification head
   - Fine-tune on labeled data

2. **Feature Extraction:**
   - Use PhoBERT embeddings
   - Train classifier on top

**Training Strategy:**
- Learning rate: 2e-5 to 5e-5
- Warmup steps
- Gradient accumulation
- Mixed precision training (FP16)

**Optimization:**
- AdamW optimizer
- Linear learning rate schedule with warmup
- Gradient clipping

**Output:**
- Fine-tuned PhoBERT model
- Tokenizer
- State-of-the-art performance metrics

---

### 6ï¸âƒ£ **Chat_bot.ipynb** - Chatbot Application
**Má»¥c Ä‘Ã­ch:** Triá»ƒn khai á»©ng dá»¥ng chatbot phÃ¢n tÃ­ch sentiment

**Input:**
- Trained models (tá»« bÆ°á»›c 4)
- User input (real-time)

**Features:**
1. **Sentiment Prediction:**
   - Nháº­p bÃ¬nh luáº­n â†’ Dá»± Ä‘oÃ¡n sentiment
   - Hiá»ƒn thá»‹ confidence score

2. **Aspect Detection:**
   - PhÃ¢n loáº¡i chá»§ Ä‘á» cá»§a bÃ¬nh luáº­n

3. **Interactive Interface:**
   - Gradio / Streamlit UI
   - Chat-like experience

4. **Batch Analysis:**
   - Upload file â†’ PhÃ¢n tÃ­ch hÃ ng loáº¡t
   - Export káº¿t quáº£

5. **Insights & Visualization:**
   - Thá»‘ng kÃª sentiment theo thá»i gian
   - Trending topics
   - Alert cho sentiment tiÃªu cá»±c Ä‘á»™t biáº¿n

**Deployment Options:**
- Local: Jupyter Notebook
- Web: Streamlit/Gradio
- API: FastAPI/Flask
- Cloud: Hugging Face Spaces, Google Colab

---

## ğŸ”§ CÃ”NG NGHá»† & THÆ¯ VIá»†N Sá»¬ Dá»¤NG

### Data Processing
```python
- pandas
- numpy
- json
```

### NLP & Text Processing
```python
- VnCoreNLP / PyVi (Vietnamese tokenization)
- underthesea (Vietnamese NLP)
- nltk
- spacy
- transformers (Hugging Face)
```

### Machine Learning
```python
- scikit-learn
- xgboost
- lightgbm
```

### Deep Learning
```python
- tensorflow / keras
- pytorch
- gensim (Word2Vec)
```

### Visualization
```python
- matplotlib
- seaborn
- plotly
- wordcloud
```

### AI APIs
```python
- google-generativeai (Gemini)
```

### Deployment
```python
- gradio
- streamlit
- fastapi
- flask
```

---

## ğŸ“Š LUá»’NG Dá»® LIá»†U CHI TIáº¾T

```
Data.json (Raw)
    â”‚
    â”œâ”€â†’ [CheckData.ipynb]
    â”‚       â”‚
    â”‚       â””â”€â†’ Gemini AI Processing
    â”‚               â”‚
    â”‚               â””â”€â†’ Data_T9_Labeled_Final.json
    â”‚
    â””â”€â†’ [EDA_Data.ipynb]
            â”‚
            â”œâ”€â†’ Statistics & Insights
            â”œâ”€â†’ Visualizations
            â””â”€â†’ Data Quality Report
                    â”‚
                    â”œâ”€â†’ [MachineLearningModel.ipynb]
                    â”‚       â”‚
                    â”‚       â”œâ”€â†’ TF-IDF Features
                    â”‚       â”œâ”€â†’ Train: LR, SVM, RF, XGB...
                    â”‚       â””â”€â†’ best_ml_model.pkl
                    â”‚
                    â”œâ”€â†’ [DeepLearningModel.ipynb]
                    â”‚       â”‚
                    â”‚       â”œâ”€â†’ Word Embeddings
                    â”‚       â”œâ”€â†’ Train: LSTM, GRU, CNN...
                    â”‚       â””â”€â†’ best_dl_model.h5
                    â”‚
                    â””â”€â†’ [PhoBertModel.ipynb]
                            â”‚
                            â”œâ”€â†’ PhoBERT Fine-tuning
                            â””â”€â†’ phobert_finetuned/
                                    â”‚
                                    â””â”€â†’ [Chat_bot.ipynb]
                                            â”‚
                                            â””â”€â†’ Production Chatbot
```

---

## ğŸ¯ HÆ¯á»šNG DáºªN THá»°C HIá»†N Tá»ªNG BÆ¯á»šC

### BÆ°á»›c 1: Chuáº©n bá»‹ mÃ´i trÆ°á»ng
```bash
# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# CÃ i Ä‘áº·t dependencies
pip install pandas numpy matplotlib seaborn
pip install scikit-learn xgboost lightgbm
pip install tensorflow torch transformers
pip install google-generativeai
pip install underthesea vncorenlp
pip install gradio streamlit
```

### BÆ°á»›c 2: GÃ¡n nhÃ£n dá»¯ liá»‡u
```bash
# Cháº¡y CheckData.ipynb
jupyter notebook CheckData.ipynb

# Hoáº·c convert sang .py vÃ  cháº¡y
jupyter nbconvert --to script CheckData.ipynb
python CheckData.py
```

### BÆ°á»›c 3: PhÃ¢n tÃ­ch dá»¯ liá»‡u
```bash
# Cháº¡y EDA_Data.ipynb
jupyter notebook EDA_Data.ipynb
```

### BÆ°á»›c 4: Train models (song song)
```bash
# CÃ³ thá»ƒ cháº¡y song song 3 notebooks
jupyter notebook MachineLearningModel.ipynb
jupyter notebook DeepLearningModel.ipynb
jupyter notebook PhoBertModel.ipynb
```

### BÆ°á»›c 5: So sÃ¡nh & chá»n model tá»‘t nháº¥t
- Xem káº¿t quáº£ tá»« 3 notebooks
- So sÃ¡nh metrics
- Chá»n model cÃ³ F1-score cao nháº¥t

### BÆ°á»›c 6: Deploy chatbot
```bash
# Cháº¡y Chat_bot.ipynb
jupyter notebook Chat_bot.ipynb

# Hoáº·c deploy vá»›i Streamlit
streamlit run chatbot_app.py
```

---

## ğŸ“ˆ Káº¾T QUáº¢ MONG Äá»¢I

### Performance Benchmarks
| Model Type | Expected Accuracy | F1-Score | Training Time |
|-----------|------------------|----------|---------------|
| Logistic Regression | 75-80% | 0.73-0.78 | < 1 min |
| SVM | 78-82% | 0.76-0.80 | 2-5 min |
| Random Forest | 80-84% | 0.78-0.82 | 3-7 min |
| XGBoost | 82-86% | 0.80-0.84 | 5-10 min |
| LSTM | 84-88% | 0.82-0.86 | 20-40 min |
| CNN-LSTM | 85-89% | 0.83-0.87 | 25-45 min |
| PhoBERT | **88-92%** | **0.86-0.90** | 1-2 hours |

---

## ğŸš€ TIPS & BEST PRACTICES

### 1. Data Quality
- âœ… LuÃ´n kiá»ƒm tra data quality trÆ°á»›c khi train
- âœ… CÃ¢n báº±ng dataset náº¿u cÃ³ class imbalance
- âœ… Sá»­ dá»¥ng stratified split Ä‘á»ƒ giá»¯ tá»· lá»‡ nhÃ£n

### 2. Model Training
- âœ… Báº¯t Ä‘áº§u vá»›i baseline model Ä‘Æ¡n giáº£n (Logistic Regression)
- âœ… Sá»­ dá»¥ng cross-validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
- âœ… LÆ°u láº¡i táº¥t cáº£ experiments (MLflow, Weights & Biases)

### 3. Hyperparameter Tuning
- âœ… DÃ¹ng Grid Search cho khÃ´ng gian nhá»
- âœ… DÃ¹ng Random Search hoáº·c Bayesian Optimization cho khÃ´ng gian lá»›n
- âœ… Theo dÃµi overfitting vá»›i validation set

### 4. Deployment
- âœ… Versioning cho models
- âœ… A/B testing trÆ°á»›c khi deploy production
- âœ… Monitoring model performance trong production

---

## ğŸ“ TROUBLESHOOTING

### Váº¥n Ä‘á» thÆ°á»ng gáº·p:

**1. Gemini API Rate Limit**
```python
# Solution: TÄƒng sleep time giá»¯a cÃ¡c batch
SLEEP_TIME = 5  # thay vÃ¬ 2
```

**2. Out of Memory khi train DL**
```python
# Solution: Giáº£m batch size
batch_size = 16  # thay vÃ¬ 32
```

**3. PhoBERT quÃ¡ cháº­m**
```python
# Solution: Sá»­ dá»¥ng phobert-base thay vÃ¬ phobert-large
model_name = "vinai/phobert-base"
```

**4. Accuracy tháº¥p**
- Kiá»ƒm tra data quality
- Thá»­ data augmentation
- TÄƒng sá»‘ lÆ°á»£ng training data
- Thá»­ ensemble methods

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

- [PhoBERT Paper](https://arxiv.org/abs/2003.00744)
- [Gemini API Documentation](https://ai.google.dev/docs)
- [Vietnamese NLP Resources](https://github.com/undertheseanlp/underthesea)
- [Sentiment Analysis Best Practices](https://www.tensorflow.org/tutorials/text/text_classification_rnn)

---

## ğŸ‘¥ CONTRIBUTORS & MAINTENANCE

**Dá»± Ã¡n:** PhÃ¢n tÃ­ch cáº£m xÃºc thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam  
**NgÃ y táº¡o:** 2026  
**Version:** 1.0  

---

**ğŸ‰ ChÃºc báº¡n thÃ nh cÃ´ng vá»›i dá»± Ã¡n!**
