{"cells":[{"cell_type":"code","execution_count":null,"id":"ccd66842","metadata":{"id":"ccd66842"},"outputs":[],"source":["import google.generativeai as genai\n","import time\n","import json\n","import pandas as pd\n","import sys\n","\n","# 1. Cáº¤U HÃŒNH API KEY\n","# Thay API Key cá»§a báº¡n vÃ o Ä‘Ã¢y\n","API_KEY = \"AIzaSyArdOa8r86_DfY2_EiGcpLNHcTPQiTV15E\"\n","genai.configure(api_key=API_KEY)\n","\n","# 2. CHá»ŒN MODEL (Gemma-3-27b-it: Miá»…n phÃ­ & Máº¡nh máº½)\n","MODEL_NAME = \"gemma-3-27b-it\"\n","\n","try:\n","    model = genai.GenerativeModel(MODEL_NAME)\n","except Exception as e:\n","    print(f\"âŒ Lá»—i khá»Ÿi táº¡o model: {e}\")\n","    sys.exit(1)\n","\n","def clean_json_string(text):\n","    \"\"\"LÃ m sáº¡ch chuá»—i JSON tá»« pháº£n há»“i cá»§a AI\"\"\"\n","    text = text.strip()\n","    # Loáº¡i bá» markdown code block\n","    if text.startswith(\"```json\"): text = text[7:]\n","    elif text.startswith(\"```\"): text = text[3:]\n","    if text.endswith(\"```\"): text = text[:-3]\n","    return text.strip()\n","\n","def analyze_batch(items_with_id):\n","    \"\"\"\n","    Gá»­i danh sÃ¡ch comment kÃ¨m ID.\n","    Prompt NÃ‚NG CAO: Lá»c rÃ¡c, tá»¥c tÄ©u, spam vÃ  ná»™i dung khÃ´ng liÃªn quan.\n","    \"\"\"\n","\n","    # Chá»‰ láº¥y ID vÃ  Text Ä‘á»ƒ gá»­i cho AI\n","    mini_batch = [{\"id\": item[\"id\"], \"text\": item[\"text\"]} for item in items_with_id]\n","\n","    # --- PROMPT \"Bá»˜ Lá»ŒC NGHIÃŠM NGáº¶T\" ---\n","    prompt = f\"\"\"\n","    Báº¡n lÃ  má»™t Trá»£ lÃ½ AI chuyÃªn lá»c vÃ  phÃ¢n loáº¡i dá»¯ liá»‡u chá»©ng khoÃ¡n (Stock Data Cleaner).\n","\n","    NHIá»†M Vá»¤ Cá»¦A Báº N LÃ€ 2 BÆ¯á»šC:\n","\n","    BÆ¯á»šC 1: KIá»‚M DUYá»†T & Lá»ŒC Bá»Ž (Quan trá»ng nháº¥t)\n","    HÃ£y loáº¡i bá» ngay láº­p tá»©c (KHÃ”NG Ä‘Æ°a vÃ o káº¿t quáº£) náº¿u comment thuá»™c cÃ¡c nhÃ³m sau:\n","    1. ðŸ”ž Tá»¥c tÄ©u, Pháº£n cáº£m: CÃ¡c tá»« ngá»¯ thÃ´ tá»¥c, bá»™ pháº­n cÆ¡ thá»ƒ nháº¡y cáº£m (VD: \"vÃº to\", \"lÃ m tÃ¬nh\", chá»­i báº­y vÃ´ vÄƒn hÃ³a khÃ´ng liÃªn quan thá»‹ trÆ°á»ng).\n","    2. ðŸ‘‹ ChÃ o há»i xÃ£ giao vÃ´ nghÄ©a: \"ChÃ o cáº£ nhÃ \", \"Hello\", \"ChÃºc ngÃ y má»›i\", \"Äiá»ƒm danh\".\n","    3. ðŸ“¢ Spam quáº£ng cÃ¡o: Rao bÃ¡n sim, sá»‘ Ä‘á», quáº£ng cÃ¡o khÃ´ng liÃªn quan chá»©ng khoÃ¡n.\n","    4. ðŸ—‘ï¸ RÃ¡c/Nonsense: Chá»‰ cÃ³ icon, hoáº·c 1-2 tá»« vÃ´ nghÄ©a khÃ´ng rÃµ ngá»¯ cáº£nh.\n","\n","    LÆ¯U Ã Äáº¶C BIá»†T:\n","    - GIá»® Láº I cÃ¡c tá»« lÃ³ng Ä‘áº·c thÃ¹ chá»©ng khoÃ¡n dÃ¹ nghe hÆ¡i thÃ´ (VD: \"bÃ´\", \"chim lá»£n\", \"bÃ¬m bá»‹p\", \"toang\", \"mÃ¡u cháº£y thÃ nh sÃ´ng\", \"vá» mÃ¡ng lá»£n\"). ÄÃ¢y lÃ  cáº£m xÃºc thá»‹ trÆ°á»ng há»£p lá»‡.\n","    - CHá»ˆ Lá»ŒC Bá»Ž nhá»¯ng thá»© hoÃ n toÃ n khÃ´ng liÃªn quan Ä‘áº¿n Ä‘áº§u tÆ°/tÃ i chÃ­nh.\n","\n","    BÆ¯á»šC 2: GÃN NHÃƒN (Chá»‰ vá»›i cÃ¡c comment há»£p lá»‡ cÃ²n láº¡i)\n","    - Sentiment: TÃ­ch cá»±c / TiÃªu cá»±c / BÃ¬nh thÆ°á»ng.\n","    - Aspect: Diá»…n biáº¿n giÃ¡ / Kinh doanh / ChÃ­nh sÃ¡ch / Cáº£m xÃºc / Chiáº¿n lÆ°á»£c / Sá»± kiá»‡n / KhÃ¡c.\n","\n","    INPUT DATA:\n","    {json.dumps(mini_batch, ensure_ascii=False)}\n","\n","    YÃŠU Cáº¦U OUTPUT:\n","    - Tráº£ vá» JSON Array chá»‰ chá»©a cÃ¡c comment ÄÃƒ ÄÆ¯á»¢C DUYá»†T.\n","    - KHÃ”NG giáº£i thÃ­ch.\n","    - Cáº¥u trÃºc:\n","    {{\n","        \"id\": (giá»¯ nguyÃªn),\n","        \"sentiment\": \"...\",\n","        \"aspect\": \"...\"\n","    }}\n","    \"\"\"\n","\n","    try:\n","        response = model.generate_content(\n","            prompt,\n","            generation_config={\n","                \"temperature\": 0.0, # Äáº·t vá» 0 Ä‘á»ƒ AI cá»±c ká»³ nghiÃªm tÃºc, khÃ´ng sÃ¡ng táº¡o\n","            }\n","        )\n","\n","        json_str = clean_json_string(response.text)\n","        return json.loads(json_str)\n","\n","    except Exception as e:\n","        print(f\"âš ï¸ Lá»—i xá»­ lÃ½ batch: {e}\")\n","        return None\n","\n","def process_file(input_file, output_file):\n","    try:\n","        # Äá»c file JSON input (dáº¡ng list object)\n","        with open(input_file, 'r', encoding='utf-8') as f:\n","            raw_data = json.load(f)\n","    except Exception as e:\n","        print(f\"âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file {input_file}: {e}\")\n","        return\n","\n","    # Chuáº©n bá»‹ dá»¯ liá»‡u: ThÃªm ID táº¡m thá»i Ä‘á»ƒ map káº¿t quáº£\n","    processing_data = []\n","    for idx, item in enumerate(raw_data):\n","        # Äáº£m báº£o cÃ³ trÆ°á»ng text\n","        text_content = item.get('text') or item.get('content') or \"\"\n","\n","        # Táº¡o object táº¡m Ä‘á»ƒ xá»­ lÃ½\n","        temp_obj = {\n","            \"id\": idx,                  # ID Ä‘á»ƒ khá»›p káº¿t quáº£ sau khi AI tráº£ vá»\n","            \"text\": text_content,\n","            \"original_item\": item       # Giá»¯ láº¡i toÃ n bá»™ dá»¯ liá»‡u gá»‘c (date, source...)\n","        }\n","        processing_data.append(temp_obj)\n","\n","    final_results = []\n","\n","    # Cáº¥u hÃ¬nh cháº¡y\n","    BATCH_SIZE = 20    # Gemma xá»­ lÃ½ tá»‘t 20 dÃ²ng/láº§n\n","    SLEEP_TIME = 2     # Gemma háº¡n má»©c cao, chá»‰ cáº§n nghá»‰ nháº¹ 2s\n","\n","    print(f\"ðŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ {len(processing_data)} dÃ²ng vá»›i model {MODEL_NAME}...\")\n","\n","    for i in range(0, len(processing_data), BATCH_SIZE):\n","        batch_items = processing_data[i : i + BATCH_SIZE]\n","        print(f\"â³ Batch {i//BATCH_SIZE + 1}: DÃ²ng {i+1} -> {min(i+BATCH_SIZE, len(processing_data))}...\")\n","\n","        success = False\n","        retry = 0\n","\n","        batch_final_objs = []  # Ä‘á»ƒ lÆ°u táº¡m batch nÃ y\n","\n","        while not success and retry < 3:\n","            # Gá»­i Ä‘i phÃ¢n tÃ­ch\n","            ai_results = analyze_batch(batch_items)\n","\n","            if ai_results:\n","                # --- KHÃ‚U QUAN TRá»ŒNG: GHÃ‰P Dá»® LIá»†U ---\n","                # GhÃ©p káº¿t quáº£ AI (sentiment, aspect) vÃ o dá»¯ liá»‡u gá»‘c (date, source)\n","                # Dá»±a vÃ o ID Ä‘á»ƒ ghÃ©p cho chÃ­nh xÃ¡c\n","                for ai_item in ai_results:\n","                    matching_original = next((x for x in batch_items if x[\"id\"] == ai_item.get(\"id\")), None)\n","                    if matching_original:\n","                        # Táº¡o object káº¿t quáº£ cuá»‘i cÃ¹ng theo Ä‘Ãºng format áº£nh yÃªu cáº§u\n","                        orig = matching_original[\"original_item\"]\n","                        final_obj = {\n","                            \"text\": orig.get(\"text\", \"\"),\n","                            \"aspect\": ai_item.get(\"aspect\", \"KhÃ¡c\"),\n","                            \"sentiment\": ai_item.get(\"sentiment\", \"BÃ¬nh thÆ°á»ng\"),\n","                            \"date\": orig.get(\"date\", \"\"),  # <- Sá»­a Ä‘Ãºng theo yÃªu cáº§u\n","                            \"source\": orig.get(\"source\", \"Unknown\"),\n","                            \"raw\": orig.get(\"raw\") or orig.get(\"text\", \"\") # raw thÆ°á»ng giá»‘ng text\n","                        }\n","                        batch_final_objs.append(final_obj)\n","                final_results.extend(batch_final_objs)\n","                success = True\n","                print(f\"âœ… Xong batch. Nghá»‰ {SLEEP_TIME}s... Hiá»ƒn thá»‹ 5 dÃ²ng Ä‘áº§u batch nÃ y dÆ°á»›i dáº¡ng khung pandas:\")\n","                if batch_final_objs:\n","                    df_preview = pd.DataFrame(batch_final_objs)\n","                    print(df_preview.head(5).to_string(index=False, justify='center', col_space=18))\n","                    print(\"-\" * 80)\n","                else:\n","                    print(\"KhÃ´ng cÃ³ dá»¯ liá»‡u trong batch nÃ y!\")\n","                time.sleep(SLEEP_TIME)\n","            else:\n","                retry += 1\n","                print(f\"âŒ Lá»—i batch. Thá»­ láº¡i láº§n {retry} (Äá»£i 5s)...\")\n","                time.sleep(5)\n","\n","    # LÆ°u káº¿t quáº£ ra file JSON chuáº©n\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        json.dump(final_results, f, ensure_ascii=False, indent=2)\n","\n","    print(f\"ðŸŽ‰ HOÃ€N Táº¤T! File káº¿t quáº£ chuáº©n JSON: {output_file}\")\n","    # In thá»­ 1 dÃ²ng Ä‘á»ƒ kiá»ƒm tra\n","    if final_results:\n","        print(\"\\n--- Máº«u káº¿t quáº£ ---\")\n","        print(json.dumps(final_results[0], ensure_ascii=False, indent=2))\n","\n","# --- CHáº Y CHÆ¯Æ NG TRÃŒNH ---\n","if __name__ == \"__main__\":\n","    # Thay tÃªn file Ä‘Ãºng cá»§a báº¡n vÃ o Ä‘Ã¢y\n","    INPUT_FILE = \"Data_T9_Reduce.json\"\n","    OUTPUT_FILE = \"Data_T9_Labeled_Final.json\"\n","\n","    process_file(INPUT_FILE, OUTPUT_FILE)"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}